{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped screenshot saved!\n",
      "Geolocation data added to detected_object_cropped.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "\n",
    "# Function to convert latitude/longitude to EXIF-friendly format\n",
    "def convert_to_degrees(value):\n",
    "    degrees = int(value)\n",
    "    minutes = int((value - degrees) * 60)\n",
    "    seconds = (value - degrees - minutes / 60) * 3600\n",
    "    return (degrees, minutes, seconds)\n",
    "\n",
    "# Function to add GPS metadata to the image\n",
    "def add_gps_data(image_path, lat, lon):\n",
    "    img = Image.open(image_path)\n",
    "    exif_data = img.getexif()\n",
    "    gps_info = {}\n",
    "    \n",
    "    # Convert latitude and longitude to EXIF format\n",
    "    lat_deg = convert_to_degrees(abs(lat))\n",
    "    lon_deg = convert_to_degrees(abs(lon))\n",
    "\n",
    "    gps_info[1] = 'N' if lat >= 0 else 'S'  # Latitude Ref\n",
    "    gps_info[2] = lat_deg  # Latitude\n",
    "    gps_info[3] = 'E' if lon >= 0 else 'W'  # Longitude Ref\n",
    "    gps_info[4] = lon_deg  # Longitude\n",
    "\n",
    "    # Write the GPS data back into the image\n",
    "    exif_data[0x8825] = gps_info  # GPSInfo tag\n",
    "    img.save(image_path, exif=exif_data)\n",
    "    print(f\"Geolocation data added to {image_path}\")\n",
    "\n",
    "# Prompt user for latitude and longitude input\n",
    "latitude = float(input(\"Enter latitude: \"))\n",
    "longitude = float(input(\"Enter longitude: \"))\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Read the first frame as the background\n",
    "ret, background = cap.read()\n",
    "\n",
    "# Convert the background to grayscale\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur to the background to reduce noise\n",
    "background_blur = cv2.GaussianBlur(background_gray, (21, 21), 0)\n",
    "\n",
    "# Screen center coordinates\n",
    "height, width = background.shape[:2]\n",
    "center_x, center_y = width // 2, height // 2\n",
    "\n",
    "# Flag to prevent multiple screenshots\n",
    "screenshot_taken = False\n",
    "\n",
    "def is_centered(x, y, w, h):\n",
    "    \"\"\" Check if the object is near the center of the screen \"\"\"\n",
    "    obj_center_x = x + w // 2\n",
    "    obj_center_y = y + h // 2\n",
    "    # Define a region around the center for detection\n",
    "    tolerance = 50\n",
    "    return (center_x - tolerance < obj_center_x < center_x + tolerance) and \\\n",
    "           (center_y - tolerance < obj_center_y < center_y + tolerance)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the current frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to the frame to reduce noise\n",
    "    gray_blur = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    \n",
    "    # Compute the absolute difference between the background and the current frame\n",
    "    diff = cv2.absdiff(background_blur, gray_blur)\n",
    "    \n",
    "    # Apply a threshold to get the foreground mask\n",
    "    _, mask = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Invert the mask to get the background mask\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    \n",
    "    # Create a white background of the same size as the frame\n",
    "    white_background = np.full_like(frame, 255)\n",
    "    \n",
    "    # Use the mask to extract the moving object from the current frame\n",
    "    foreground = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    # Use the inverse mask to extract the background from the white background\n",
    "    white_bg = cv2.bitwise_and(white_background, white_background, mask=mask_inv)\n",
    "    \n",
    "    # Combine the foreground (moving object) with the white background\n",
    "    result = cv2.add(foreground, white_bg)\n",
    "    \n",
    "    # Find contours to detect the moving object\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Iterate over the contours to draw bounding boxes\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:  # Filter small objects\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # Draw a bounding box around the object\n",
    "            cv2.rectangle(result, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Check if the object is passing through the center\n",
    "            if is_centered(x, y, w, h) and not screenshot_taken:\n",
    "                screenshot_taken = True\n",
    "\n",
    "                # Get the center of the bounding box\n",
    "                obj_center_x = x + w // 2\n",
    "                obj_center_y = y + h // 2\n",
    "                \n",
    "                # Calculate the crop area for 400x400 image centered on the bounding box center\n",
    "                crop_x = max(0, obj_center_x - 200)\n",
    "                crop_y = max(0, obj_center_y - 200)\n",
    "                crop_x2 = min(width, crop_x + 400)\n",
    "                crop_y2 = min(height, crop_y + 400)\n",
    "                \n",
    "                # Ensure the crop is exactly 400x400\n",
    "                if (crop_x2 - crop_x) < 400:\n",
    "                    crop_x = max(0, crop_x2 - 400)\n",
    "                if (crop_y2 - crop_y) < 400:\n",
    "                    crop_y = max(0, crop_y2 - 400)\n",
    "                \n",
    "                # Crop the image around the center of the bounding box\n",
    "                cropped_result = result[crop_y:crop_y2, crop_x:crop_x2]\n",
    "                \n",
    "                # Save the cropped screenshot\n",
    "                image_path = 'detected_object_cropped.png'\n",
    "                cv2.imwrite(image_path, cropped_result)\n",
    "                print(\"Cropped screenshot saved!\")\n",
    "\n",
    "                # Add geolocation metadata to the image\n",
    "                add_gps_data(image_path, latitude, longitude)\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow('Moving Object with White Background', result)\n",
    "    \n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
